# Super Resulution GAN and Enchanced Super Resolution GAN test implementation

В данном проекте проведена тестовая реализация следующих алгоритмов генеративных состязательных сетей:
    - Super Resulution GAN (SRGAN)
    - Enchanced Super Resolution GAN (ESRGAN)

## SRGAN
Реализация модели основана на оригинальной статье, которая доступна по следующему адресу: https://arxiv.org/abs/1609.04802

Поскольку в данной статье не приводится основной код модели и реализация некоторых моментов не очень понятна из содержания статьи, предложенный код реализации может отличаться от описанного авторами. При этом была предпринята попытка макисмально следовать тексту документа при реализации всей архитектуры модели и последовательности обучения.

Для реализации модели частично использовался код для загрузки и первичной обработки датасета, доступный здесь: https://github.com/aladdinpersson/Machine-Learning-Collection. Также из данного репозитария заимствован код расчета VGG loss, описанный в статье.

В качестве тестового и валидационного датасета использовался широко известный DIV2k dataset: https://data.vision.ee.ethz.ch/cvl/DIV2K/. Данный датасет состоит из 800 тренинговых и 100 валидационных изображений, доступных как в высоком, так и в сниженном качестве. Для обучения в тренинговых изображениях вырезались случайные фрагменты размером 96 х 96 пикселей, для них проводился downsampling в 4 раза по методу bicubic (аналогично оригинальной статье). После этого проводится обучение генеративно-состязательной сети для повышения разрешения полученного фрагмента в 4 раза и нахождения максимального соответствия оригинальному фрагменту.

Обучение проводилось в два этапа (как рекомендовано в оригинальной статье):

    1. Обучение только генератора (SRResNet), дискриминатор не используется.
        300 эпох (15К итераций) learning rate 1e-4
    2.  Обучение сети GAN (аналогично алгоритму оригинальной статьи)
        2000 эпох (100К итераций) learning rate 1e-4
        2000 эпох (100К итераций) learning rate 1e-5

Полученный результат позволяет получить хорошие результаты по повышению разрешения тестовых изображений. 
Результат может отличаться от описанного в статье, поскольку в оригинале использовался тренинговый датасет значительно больших размеров и обучение производилось на большем числе итераций.

Для численной оценки результатов на этапе валидации использовался показатель PSNR (Peak signal-to-noise ratio), но для Super-Resolution он не является объективным показателем, так как учитывает только MSE метрику, приводящую в значительной мере к получению размытого изображения. Полученный средний показатель PSNR на валидационной выборке: 27.1458

Полученная модель GAN является Fully Convolutional, поэтому она не зависит от размера входного изображения. На вход модели можно подавать изображения любого размера (до тех пор, пока они будут помещаться в память GPU), и на выходе получать изображения с улучшенным в 4 раза разрешением.

Также для обучения использовались фрагменты размером 96 х 96 пикселей и показатель увеличения разрешения - 4. Данные предустановки никак не влияют на архитектуру сети и могут быть заменены на другие размерности в конфигурационном файле модели, после чего может потребоваться переобучение модели.

## ESRGAN
Реализация модели основана на оригинальной статье, которая доступна по следующему адресу: https://arxiv.org/abs/1809.00219

Согласно оригинальной статье, ESRGAN базируется на общей арзитектуре SRGAN и использует неизменную архитектуру дискриминатора, при этом архитектура генератора изменена полностью. Так же изменены предобработка изображений и используемые для обучения функции потерь. Поэтому для реализации модели пришлось значительно модифицировать исходный код SRGAN.

Как и в случае SRGAN, была предпринята попытка реализации кода модели максимально близко к оригинальному тексту статьи. При реализации архитектуры модели частично использовались фрагменты года, прикрепленного к оригиналу статьи, так как некоторые тонкости архитектуры в самой статье либо не описаны, либо описаны с ошибками относительно прикрепленного кода.
Кроме того, часть кода для реализации функций потерь была заимствована из следующего репозитария: https://github.com/Lornatang/ESRGAN-PyTorch.

В качестве тестового и валидационного датасета использовался DIV2k dataset. Для обучения в тренинговых изображениях вырезались случайные фрагменты размером 128 х 128 пикселей (отличие от SRGAN - использование фрагментов большего размера), для них проводился downsampling в 4 раза по методу bicubic (аналогично оригинальной статье). После этого проводится обучение генеративно-состязательной сети для повышения разрешения полученного фрагмента в 4 раза и нахождения максимального соответствия оригинальному фрагменту.

Обучение проводилось в два этапа (как рекомендовано в оригинальной статье):

    1. Обучение только генератора (SRResNet), дискриминатор не используется.
        4000 эпох (200К итераций) learning rate 1e-4
        4000 эпох (200К итераций) learning rate 5e-5
    2.  Обучение сети GAN (аналогично алгоритму оригинальной статьи)
        1000 эпох (50К итераций) learning rate 1e-4
        1000 эпох (50К итераций) learning rate 5e-5
        2000 эпох (100К итераций) learning rate 2.5e-5
        2000 эпох (100К итераций) learning rate 1.25e-5
        2000 эпох (100К итераций) learning rate 6.25e-6

Полученный результат позволяет получить хорошие результаты по повышению разрешения тестовых изображений. 
Результат может отличаться от описанного в статье, поскольку в оригинале использовался тренинговый датасет значительно больших размеров и обучение производилось на большем числе итераций.

Для численной оценки результатов на этапе валидации использовался показатель PSNR (Peak signal-to-noise ratio). Полученный средний показатель PSNR на валидационной выборке: 26.7632, что несколько хуже, чем результат SRGAN. Но, как ранее отмечено, данный показатель не является определяющим для Super Resolution, и определяющим показателем является визуальная оценка изображения, которая субъективно обеспечивает более высокое качество по сравнению с SRGAN.

Полученная модель ESRGAN также является Fully Convolutional, поэтому для нее справедливы те же возможности, которые были ранее описаны для SRGAN (нет зависимости от размера входного изображения, размера фрагмента обучения, кратности увеличения размерности).

## Структура проекта
    /srgan - корневой каталог проекта
        /bin - скрипты для инициализации модели
            downlod_train.sh - скрипт загрузки датасета для тренировки моделей
            download_val.sh - скрипт загрузки датасетов для валидации моделей
            download_weights.sh - скрипт загрузки весов предобученных моделей
        /ipynb - блокноты, использовавшиеся для тренировки и валидации моделей
            ESRgan_train.ipynb
            ESRgan_valid.ipynb
            SRgan_train.ipynb
            SRgan_valid.ipynb
        /result_images - каталог с образцами изображений на выходе моделей
        /src - каталог с кодом моделей
            test_esrgan.py - скрипт для повышения размерности изображений на основе предобученной ESRGAN
            test_srgan.py - скрипт для повышения размерности изображений на основе предобученной SRGAN 
            train_esrgan.py - скрипт обучения ESRGAN
            train_srgan.py - скрипт обучения SRGAN
            val_esrgan.py - скрипт валидации предобученной модели ESRGAN
            val_srgan.py - скрипт валидации предобученной модели SRGAN
            /esrgan - модель ESRGAN
                config.py - файл конфигурации
                dataload.py - файл с кодом загрузки и предобработки изображений
                model.py - модель генератора и дискриминатора
                utils.py - служебные функции
            /srgan - модель SRGAN
                config.py - файл конфигурации
                dataload.py - файл с кодом загрузки и предобработки изображений
                model.py - модель генератора и дискриминатора
                utils.py - служебные функции
        /test_images - каталог для размещения изображений, подаваемых на вход моделей
        requirements.txt - список требуемых программных пакетов

Примечание: все скрипты необходимо запускать из корневого каталога проекта для обеспечения корректного доступа к загружаемым данным и модулям.